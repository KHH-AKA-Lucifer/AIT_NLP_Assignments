{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d97b8fa",
   "metadata": {},
   "source": [
    "## A2 Language Modeling \n",
    "\n",
    "### Task 1: Dataset Acquisition \n",
    "\n",
    "I'm a big StarWar fun. I searched through the Internet and found this dataset on Github that has all character background and the story line in a single source. One little problem is they are all in html file. Therefore, I need to remove the html tags from the file and extract the text only.\n",
    "\n",
    "Data Source: https://github.com/AlbertoFormaggio1/star_wars_unstructured_dataset/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "157d6683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries \n",
    "import re\n",
    "from pathlib import Path \n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31217999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset path \n",
    "dataset_dir = Path(\"starwars_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b3ed578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def html2txt(html:str) -> str:\n",
    "\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    # remove html tags\n",
    "    for tag in soup(['script', 'style', 'noscript', 'header', 'footer', 'nav', 'aside']):\n",
    "        tag.decompose()\n",
    "\n",
    "    \n",
    "    # get the text \n",
    "    text = soup.get_text(separator=' ')\n",
    "\n",
    "    # normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a5adf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize empty list \n",
    "docs = []\n",
    "meta_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc614943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of HTML files: 242\n"
     ]
    }
   ],
   "source": [
    "html_files = sorted(dataset_dir.glob('*.html'))\n",
    "print(\"# of HTML files:\", len(html_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96abe876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [00:00<00:00, 1643.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usable documents: 151\n",
      "Sample text: Abafar A desert planet located in the Outer Rim with a completely white surface. Known as The Void, the planet is barely populated but is home to massive amounts of rhydonium, a scarce and volatile fuel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for fp in tqdm(html_files):\n",
    "    html = fp.read_text(encoding='utf-8', errors='ignore')\n",
    "    text = html2txt(html)\n",
    "\n",
    "    if len(text) < 200:\n",
    "        continue \n",
    "\n",
    "    docs.append(text)\n",
    "    meta_data.append(fp.name)\n",
    "\n",
    "\n",
    "# no. of usable documents\n",
    "print('Usable documents:', len(docs))\n",
    "# sample text \n",
    "print('Sample text:', docs[0][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21fa7387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: /Users/kaungheinhtet/Desktop/AIT_NLP_Assignments/A2_Language_Modeling/starwars_dataset/starwars_corpus.txt\n",
      "Total characters: 614127\n"
     ]
    }
   ],
   "source": [
    "# form corpus \n",
    "corpus = '\\n\\n'.join(docs)\n",
    "# define output path \n",
    "out_path = Path('starwars_dataset/starwars_corpus.txt')\n",
    "out_path.write_text(corpus, encoding='utf-8')\n",
    "\n",
    "print('Output:', out_path.resolve())\n",
    "print('Total characters:', len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724706ae",
   "metadata": {},
   "source": [
    "### Preprocesing\n",
    "\n",
    "We have the corpus now. However, the computer does not understand our ligustic words. It only understands the number like 0 and 1. Therfore, we need to tokenize and numericalize as usual to feed the corupus into our language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19e14c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaungheinhtet/Desktop/AIT_NLP_Assignments/.venv/lib/python3.9/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/Users/kaungheinhtet/Desktop/AIT_NLP_Assignments/.venv/lib/python3.9/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/Users/kaungheinhtet/Desktop/AIT_NLP_Assignments/.venv/lib/python3.9/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "# import required libraries \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "279dfae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -c \"import torch; print('torch', torch.__version__)\"\n",
    "# !python -c \"import importlib.metadata as m; print('torchtext', m.version('torchtext'))\"\n",
    "# !python -c \"import platform; print(platform.platform()); import struct; print('py', struct.calcsize('P')*8, 'bit')\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cb95c5",
   "metadata": {},
   "source": [
    "Let's check if we are using GPU or CPU. And also set the random seed to make sure the initialization are reproducible in all environments and devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6075a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "#make our work comparable if restarted the kernel\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de6ad07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chars: 614127\n",
      "Abafar A desert planet located in the Outer Rim with a completely white surface. Known as The Void, the planet is barely populated but is home to massive amounts of rhydonium, a scarce and volatile fuel.\n",
      "\n",
      "Admiral Ackbar Fleet Admiral Gial Ackbar is a fictional character from the Star Wars franchise.\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "corpus = Path(\"starwars_dataset/starwars_corpus.txt\")\n",
    "text = corpus.read_text(encoding=\"utf-8\")\n",
    "print(\"Chars:\", len(text))\n",
    "print(text[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c77426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use basic english tokenizer\n",
    "# splits + lowercase + basic cleaning\n",
    "tokenizer = get_tokenizer(\"basic_english\")  \n",
    "\n",
    "def yield_tokens(text):\n",
    "    # tokenize by lines to avoid huge memory spikes\n",
    "    for line in text.splitlines():\n",
    "        toks = tokenizer(line)\n",
    "        if toks:\n",
    "            yield toks\n",
    "\n",
    "specials = [\"<pad>\", \"<unk>\"]\n",
    "vocab = build_vocab_from_iterator(yield_tokens(text), specials=specials, min_freq=1)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f993d31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 5751\n",
      "Sample tokens: ['darth', 'vader', 'is', 'coming', 'to', 'tatooine', '.']\n",
      "Sample ids: [81, 70, 10, 2004, 6, 212, 4]\n"
     ]
    }
   ],
   "source": [
    "# print no. of vocab size\n",
    "vocab_size = len(vocab)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "# sample tokens and token ids\n",
    "print(\"Sample tokens:\", tokenizer(\"Darth Vader is coming to Tatooine.\"))\n",
    "print(\"Sample ids:\", vocab(tokenizer(\"Darth Vader is coming to Tatooine.\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d9f5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 117284\n",
      "First 30 ids: [3234, 8, 640, 53, 969, 9, 2, 619, 509, 15, 8, 2005, 1719, 1056, 4, 180, 14, 2, 1, 3, 2, 53, 10, 1421, 3755, 33, 10, 294, 6, 2114]\n"
     ]
    }
   ],
   "source": [
    "# numericalization\n",
    "token_ids = []\n",
    "for line in text.splitlines():\n",
    "    toks = tokenizer(line)\n",
    "    if toks:\n",
    "        token_ids.extend(vocab(toks))\n",
    "\n",
    "print(\"Total tokens:\", len(token_ids))\n",
    "print(\"First 30 ids:\", token_ids[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905a2e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([117254, 30]) Y shape: torch.Size([117254, 30])\n"
     ]
    }
   ],
   "source": [
    "# create LM sequences\n",
    "def make_lm_data(token_ids, seq_len=30):\n",
    "    xs, ys = [], []\n",
    "    for i in range(0, len(token_ids) - seq_len):\n",
    "        chunk = token_ids[i:i+seq_len+1]\n",
    "        xs.append(chunk[:-1])\n",
    "        ys.append(chunk[1:])\n",
    "    return torch.tensor(xs, dtype=torch.long), torch.tensor(ys, dtype=torch.long)\n",
    "\n",
    "SEQ_LEN = 30\n",
    "X, Y = make_lm_data(token_ids, seq_len=SEQ_LEN)\n",
    "print(\"X shape:\", X.shape, \"Y shape:\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "844a159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "dataset = TensorDataset(X, Y)\n",
    "\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7b0741",
   "metadata": {},
   "source": [
    "### Task 2: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19507189",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMLM(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=128, hidden_dim=256, num_layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=vocab[\"<pad>\"])\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        x = self.embedding(x)                 # [B, T] -> [B, T, E]\n",
    "        out, hidden = self.lstm(x, hidden)    # [B, T, H]\n",
    "        logits = self.fc(out)                 # [B, T, V]\n",
    "        return logits, hidden\n",
    "\n",
    "model = LSTMLM(vocab_size).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ceee5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=5.2681 val_loss=4.3624\n",
      "Epoch 2: train_loss=3.8701 val_loss=3.2889\n",
      "Epoch 3: train_loss=2.9474 val_loss=2.4152\n",
      "Epoch 4: train_loss=2.2467 val_loss=1.7938\n",
      "Epoch 5: train_loss=1.7592 val_loss=1.3612\n",
      "Epoch 6: train_loss=1.4174 val_loss=1.0650\n",
      "Epoch 7: train_loss=1.1721 val_loss=0.8573\n",
      "Epoch 8: train_loss=0.9932 val_loss=0.7129\n",
      "Epoch 9: train_loss=0.8628 val_loss=0.6176\n",
      "Epoch 10: train_loss=0.7674 val_loss=0.5541\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # targets are token ids\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def run_epoch(model, loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        logits, _ = model(x)  # [B, T, V]\n",
    "        loss = criterion(logits.view(-1, vocab_size), y.view(-1))\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "EPOCHS = 10\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss = run_epoch(model, train_loader, train=True)\n",
    "    val_loss = run_epoch(model, val_loader, train=False)\n",
    "    print(f\"Epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f79218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "darth vader . edwards stated , the armorer replaces chewbacca , in operation , <unk> . the character has been voiced by jon favreau in the clone wars . bossk is a supporting character in the novel novel films , with an\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "#import random\n",
    "\n",
    "def generate(model, prompt, max_new_tokens=50, temperature=1.0):\n",
    "    model.eval()\n",
    "    toks = tokenizer(prompt)\n",
    "    ids = vocab(toks)\n",
    "    x = torch.tensor([ids], dtype=torch.long).to(device)\n",
    "\n",
    "    hidden = None\n",
    "    for _ in range(max_new_tokens):\n",
    "        logits, hidden = model(x, hidden)\n",
    "        next_logits = logits[0, -1, :] / max(temperature, 1e-8)\n",
    "        probs = F.softmax(next_logits, dim=-1)\n",
    "        next_id = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "        ids.append(next_id)\n",
    "        x = torch.tensor([[next_id]], dtype=torch.long).to(device)\n",
    "\n",
    "    # decode (simple: join tokens)\n",
    "    inv_vocab = vocab.get_itos()\n",
    "    return \" \".join(inv_vocab[i] for i in ids)\n",
    "\n",
    "print(generate(model, \"darth vader\", max_new_tokens=40, temperature=0.9))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8837a05",
   "metadata": {},
   "source": [
    "After training, the LSTM language model parameters were saved using PyTorch’s state dictionary mechanism. The vocabulary mappings, token-to-index and index-to-token, were serialized separately in JSON format to ensure reproducibility and compatibility with the deployment environment. These artifacts will be later reused in the web application for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56c625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# artefacts folder \n",
    "\n",
    "artefact_dir = Path('artefacts')\n",
    "artefact_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47d9069b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: /Users/kaungheinhtet/Desktop/AIT_NLP_Assignments/A2_Language_Modeling/artefacts/starwars_lstm_model.pt\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "model_path = artefact_dir / 'starwars_lstm_model.pt'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "print(\"Model saved to:\", model_path.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23773ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab saved\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# idex -> token \n",
    "itos = vocab.get_itos()\n",
    "\n",
    "# token -> index \n",
    "stoi = {token: idx for idx, token in enumerate(itos)}\n",
    "\n",
    "with open(artefact_dir / 'vocab.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            'itos': itos,\n",
    "            'stoi': stoi\n",
    "        }, f, ensure_ascii=False, indent=2\n",
    "    )\n",
    "\n",
    "print('Vocab saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5497d593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
