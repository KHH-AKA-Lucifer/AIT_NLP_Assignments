{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f54b7ec6",
   "metadata": {},
   "source": [
    "# Task 3: Evaluation of Fine-Tuned Sentence-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd6f72dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaungheinhtet/Desktop/AIT_NLP_Assignments/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Detect device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0010006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Task 1 config and vocabulary\n",
      "Max length: 1000\n",
      "Hidden size: 256\n",
      "Encoder loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# load model artefacts (vocabulary + model configuration)\n",
    "\n",
    "ckpt = torch.load(\"artefacts/bert_mlm.pt\", map_location=\"cpu\")\n",
    "\n",
    "config = ckpt[\"config\"]      # contains architecture details\n",
    "word2id = ckpt[\"word2id\"]    # word -> index mapping\n",
    "id2word = ckpt[\"id2word\"]    # index -> word mapping\n",
    "\n",
    "PAD_ID = word2id[\"[PAD]\"]\n",
    "UNK_ID = word2id[\"[UNK]\"]\n",
    "MAX_LEN = config[\"max_len\"]     # maximum sequence length\n",
    "H = config[\"d_model\"]           # hidden size of BERT encoder\n",
    "\n",
    "print(\"Loaded Task 1 config and vocabulary\")\n",
    "print(\"Max length:\", MAX_LEN)\n",
    "print(\"Hidden size:\", H)\n",
    "\n",
    "\n",
    "\n",
    "# load encoder-only model (exported from Task 1)\n",
    "\n",
    "# this is the TorchScript encoder saved as bert_encoder.pt\n",
    "encoder = torch.jit.load(\"artefacts/bert_encoder.pt\", map_location=device)\n",
    "encoder.eval()\n",
    "\n",
    "print(\"Encoder loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3ade5e",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d15d2914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Lowercase and remove punctuation exactly like Task 1.\n",
    "    This ensures vocabulary consistency.\n",
    "    \"\"\"\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[.,!\\-]\", \"\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "def encode_sentence(sentence: str, max_len: int):\n",
    "    \"\"\"\n",
    "    Converts a sentence into:\n",
    "    - input_ids: padded token IDs\n",
    "    - attention_mask: 1 for real tokens, 0 for PAD\n",
    "    \"\"\"\n",
    "    sentence = clean_text(sentence)\n",
    "    tokens = sentence.split()\n",
    "\n",
    "    # Convert words to IDs (use UNK if word not found)\n",
    "    ids = [word2id.get(w, UNK_ID) for w in tokens][:max_len]\n",
    "    attn = [1] * len(ids)\n",
    "\n",
    "    # Pad up to MAX_LEN\n",
    "    while len(ids) < max_len:\n",
    "        ids.append(PAD_ID)\n",
    "        attn.append(0)\n",
    "\n",
    "    return ids, attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a4d0e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(token_embeddings, attention_mask):\n",
    "    \"\"\"\n",
    "    Apply mean pooling over valid (non-PAD) tokens.\n",
    "    \"\"\"\n",
    "    mask = attention_mask.unsqueeze(-1).float()   # [B,S,1]\n",
    "    summed = (token_embeddings * mask).sum(dim=1) # Sum over sequence\n",
    "    count = mask.sum(dim=1).clamp(min=1e-9)       # Avoid divide-by-zero\n",
    "    return summed / count                         # Mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2456efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned SBERT model loaded.\n"
     ]
    }
   ],
   "source": [
    "class SBERTSoftmax(nn.Module):\n",
    "    def __init__(self, encoder, hidden_size):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.classifier = nn.Linear(hidden_size * 3, 3)  # 3 NLI classes\n",
    "\n",
    "    def encode(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Encode a sentence into its embedding.\n",
    "        \"\"\"\n",
    "        segment_ids = torch.zeros_like(input_ids)   # Single segment\n",
    "        hidden = self.encoder(input_ids, segment_ids)   # [B,S,H]\n",
    "        return mean_pooling(hidden, attention_mask)     # [B,H]\n",
    "\n",
    "    def forward(self, prem_ids, prem_attn, hyp_ids, hyp_attn):\n",
    "        \"\"\"\n",
    "        Forward pass for NLI pair.\n",
    "        \"\"\"\n",
    "        u = self.encode(prem_ids, prem_attn)\n",
    "        v = self.encode(hyp_ids, hyp_attn)\n",
    "\n",
    "        # SBERT feature construction\n",
    "        features = torch.cat([u, v, torch.abs(u - v)], dim=1)\n",
    "\n",
    "        return self.classifier(features)\n",
    "\n",
    "\n",
    "# Instantiate model\n",
    "sbert = SBERTSoftmax(encoder, H).to(device)\n",
    "\n",
    "# Load fine-tuned weights from Task 2\n",
    "sbert_ckpt = torch.load(\"artefacts/sbert_softmax_snli.pt\", map_location=\"cpu\")\n",
    "sbert.load_state_dict(sbert_ckpt[\"sbert_state_dict\"])\n",
    "\n",
    "sbert.eval()\n",
    "\n",
    "print(\"Fine-tuned SBERT model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fd66ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "snli = load_dataset(\"snli\")\n",
    "snli = snli.filter(lambda x: x[\"label\"] != -1)\n",
    "\n",
    "# use subsets for faster evaluation\n",
    "val_ds = snli[\"validation\"].shuffle(seed=42).select(range(3000))\n",
    "test_ds = snli[\"test\"].shuffle(seed=42).select(range(3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b02002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    prem_ids, prem_attn = [], []\n",
    "    hyp_ids, hyp_attn = [], []\n",
    "    labels = []\n",
    "\n",
    "    for x in batch:\n",
    "        p_ids, p_att = encode_sentence(x[\"premise\"], MAX_LEN)\n",
    "        h_ids, h_att = encode_sentence(x[\"hypothesis\"], MAX_LEN)\n",
    "\n",
    "        prem_ids.append(p_ids)\n",
    "        prem_attn.append(p_att)\n",
    "        hyp_ids.append(h_ids)\n",
    "        hyp_attn.append(h_att)\n",
    "        labels.append(x[\"label\"])\n",
    "\n",
    "    return (\n",
    "        torch.tensor(prem_ids, dtype=torch.long),\n",
    "        torch.tensor(prem_attn, dtype=torch.long),\n",
    "        torch.tensor(hyp_ids, dtype=torch.long),\n",
    "        torch.tensor(hyp_attn, dtype=torch.long),\n",
    "        torch.tensor(labels, dtype=torch.long),\n",
    "    )\n",
    "\n",
    "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d861a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation: 100%|██████████| 94/94 [03:11<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Accuracy: 0.4817\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   entailment     0.6076    0.3391    0.4353      1032\n",
      "      neutral     0.4944    0.4596    0.4763       953\n",
      "contradiction     0.4272    0.6473    0.5147      1015\n",
      "\n",
      "     accuracy                         0.4817      3000\n",
      "    macro avg     0.5097    0.4820    0.4755      3000\n",
      " weighted avg     0.5106    0.4817    0.4752      3000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[350 215 467]\n",
      " [101 438 414]\n",
      " [125 233 657]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Test: 100%|██████████| 94/94 [03:25<00:00,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.4877\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   entailment     0.5939    0.3424    0.4344      1025\n",
      "      neutral     0.5188    0.4605    0.4879       988\n",
      "contradiction     0.4289    0.6657    0.5216       987\n",
      "\n",
      "     accuracy                         0.4877      3000\n",
      "    macro avg     0.5139    0.4895    0.4813      3000\n",
      " weighted avg     0.5149    0.4877    0.4807      3000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[351 210 464]\n",
      " [122 455 411]\n",
      " [118 212 657]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "\n",
    "def evaluate(loader, split_name=\"VAL\"):\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    sbert.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for prem_ids, prem_attn, hyp_ids, hyp_attn, labels in tqdm(loader, desc=f\"Evaluating {split_name}\"):\n",
    "\n",
    "            prem_ids = prem_ids.to(device)\n",
    "            prem_attn = prem_attn.to(device)\n",
    "            hyp_ids = hyp_ids.to(device)\n",
    "            hyp_attn = hyp_attn.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = sbert(prem_ids, prem_attn, hyp_ids, hyp_attn)\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    y_pred = np.concatenate(all_preds)\n",
    "    y_true = np.concatenate(all_labels)\n",
    "\n",
    "    # Accuracy\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"\\n{split_name} Accuracy: {acc:.4f}\\n\")\n",
    "\n",
    "    # Precision / Recall / F1\n",
    "    print(classification_report(y_true, y_pred,\n",
    "                                target_names=label_names,\n",
    "                                digits=4))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "\n",
    "\n",
    "# Run evaluation\n",
    "evaluate(val_loader, \"Validation\")\n",
    "evaluate(test_loader, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa1d51b",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "The fine-tuned Sentence-BERT model achieved an accuracy of 48.17% on the validation set and 48.77% on the test set. This performance is significantly above the random baseline of approximately 33% for a three-class classification task (entailment, neutral, contradiction), indicating that the model successfully learned meaningful sentence representations.\n",
    "\n",
    "The model performed best on the contradiction class, achieving recall values above 0.64 on both validation and test sets. However, recall for entailment was relatively low (≈0.34), suggesting that the model struggles to detect semantic entailment relationships accurately.\n",
    "\n",
    "The moderate overall performance can be attributed to several factors. First, the BERT model in Task 1 was pretrained on a relatively small subset of BookCorpus, limiting vocabulary coverage. Consequently, many SNLI tokens were mapped to the [UNK] token, reducing semantic richness in the embeddings. Second, the fine-tuning phase used a limited number of epochs and training samples compared to the original SBERT paper.\n",
    "\n",
    "Despite these limitations, the experimental results demonstrate that the custom BERT encoder successfully learned transferable sentence representations, which were effectively adapted using the SoftmaxLoss objective for natural language inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d8e1a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
